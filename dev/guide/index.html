<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Quick Start · MadDiff</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">MadDiff</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Introduction</a></li><li class="is-active"><a class="tocitem" href>Quick Start</a><ul class="internal"><li><a class="tocitem" href="#Automatic-Differentiation"><span>Automatic Differentiation</span></a></li><li><a class="tocitem" href="#Nonlinear-Programming"><span>Nonlinear Programming</span></a></li></ul></li><li><a class="tocitem" href="../tutorial/">How it Works</a></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox"/><label class="tocitem" for="menuitem-4"><span class="docs-label">API Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../core/">MadDiffCore</a></li><li><a class="tocitem" href="../special/">MadDiffSpecialFunctions</a></li><li><a class="tocitem" href="../models/">MadDiffModels</a></li><li><a class="tocitem" href="../moi/">MadDiffMOI</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Quick Start</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Quick Start</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sshin23/MadDiff.jl/blob/main/docs/src/guide.jl" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Getting-Started"><a class="docs-heading-anchor" href="#Getting-Started">Getting Started</a><a id="Getting-Started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-Started" title="Permalink"></a></h1><h2 id="Automatic-Differentiation"><a class="docs-heading-anchor" href="#Automatic-Differentiation">Automatic Differentiation</a><a id="Automatic-Differentiation-1"></a><a class="docs-heading-anchor-permalink" href="#Automatic-Differentiation" title="Permalink"></a></h2><p><code>MadDiff</code> provides a flexible user-interface for evaluating first/second-order derivatives of nonlinear expressions. In the following example, using <code>MadDiff</code>, we will create a function, gradient, and Hessian evaluator of the following function:</p><p class="math-container">\[f(x) = x_1^2 + e^{(x_2^{p_1})/2} + \log(x_2x_3+p_2),\]</p><p>where <span>$x$</span> is the variable vector, and <span>$p$</span> is the parameter vector.</p><p>We first import <code>MadDiff</code>.</p><pre><code class="language-julia hljs">using MadDiff</code></pre><p>First, we create a <code>Source</code> of <code>Variable</code>&#39;s.</p><pre><code class="language-julia hljs">x = Variable()</code></pre><pre><code class="nohighlight hljs">x</code></pre><p>The <code>Base.getindex!</code> function is extended so that <code>x[i]</code> for any <code>i</code> creates an expression for <span>$x_i$</span>. For example,</p><pre><code class="language-julia hljs">x[2]</code></pre><pre><code class="nohighlight hljs">x[2]</code></pre><p>We can do a similar thing for <code>Parameter</code>&#39;s.</p><pre><code class="language-julia hljs">p = Parameter()
p[1]</code></pre><pre><code class="nohighlight hljs">p[1]</code></pre><p>Now, we create the nonlienar expression expression.</p><pre><code class="language-julia hljs">expr = x[1]^2 + exp(x[2]^p[1])/2 + log(x[2]*x[3]+p[2])</code></pre><pre><code class="nohighlight hljs">x[1]^2 + exp(x[2]^p[1])/2 + log(x[2]*x[3] + p[2])</code></pre><p>The function evaluator of the above expression can be created by using <code>MadDiff.function_evaluator</code> as follows:</p><pre><code class="language-julia hljs">f = Evaluator(expr)</code></pre><pre><code class="nohighlight hljs">Evaluator:
x[1]^2 + exp(x[2]^p[1])/2 + log(x[2]*x[3] + p[2])</code></pre><p>Now for a given variable and parameter values, the function can be evaluated as follows.</p><pre><code class="language-julia hljs">x0 = [0.,0.5,1.5]
p0 = [2,0.5]
f(x0,p0)</code></pre><pre><code class="nohighlight hljs">0.8651562596580804</code></pre><p>The gradient evaluator can be created as follows:</p><pre><code class="language-julia hljs">y0 = similar(x0)
g = GradientEvaluator(expr)
g(y0,x0,p0)
y0</code></pre><pre><code class="nohighlight hljs">3-element Vector{Float64}:
 0.0
 1.8420127083438709
 0.4</code></pre><p>The Hessian evaluator can be created as follows:</p><pre><code class="language-julia hljs">z0 = zeros(3,3)
h = HessianEvaluator(expr)
h(z0,x0,p0)
z0</code></pre><pre><code class="nohighlight hljs">3×3 Matrix{Float64}:
 2.0  0.0        0.0
 0.0  0.486038   0.0
 0.0  0.32      -0.16</code></pre><p>Note that only lower-triangular entries are evaluated.</p><p>The evaluator can be constructed in a sparse format:</p><pre><code class="language-julia hljs">sh = SparseHessianEvaluator(expr);</code></pre><p>The sparse coordinates are:</p><pre><code class="language-julia hljs">sh.sparsity</code></pre><pre><code class="nohighlight hljs">4-element Vector{Tuple{Int64, Int64}}:
 (1, 1)
 (2, 2)
 (3, 2)
 (3, 3)</code></pre><p>The sparse Hessian can be evaluated as follows:</p><pre><code class="language-julia hljs">z1 = zeros(length(sh.sparsity))
sh(z1,x0,p0)
z1</code></pre><pre><code class="nohighlight hljs">4-element Vector{Float64}:
  2.0
  0.4860381250316117
  0.31999999999999995
 -0.16000000000000003</code></pre><h2 id="Nonlinear-Programming"><a class="docs-heading-anchor" href="#Nonlinear-Programming">Nonlinear Programming</a><a id="Nonlinear-Programming-1"></a><a class="docs-heading-anchor-permalink" href="#Nonlinear-Programming" title="Permalink"></a></h2><h3 id="Built-in-API"><a class="docs-heading-anchor" href="#Built-in-API">Built-in API</a><a id="Built-in-API-1"></a><a class="docs-heading-anchor-permalink" href="#Built-in-API" title="Permalink"></a></h3><p>MadDiff provides a built-in API for creating nonlinear prgogramming models and allows solving the created models using NLP solvers (in particular, those that are interfaced with <code>NLPModels</code>, such as <a href="https://github.com/JuliaSmoothOptimizers/NLPModelsIpopt.jl">NLPModelsIpopt</a> and <a href="https://github.com/MadNLP/MadNLP.jl">MadNLP</a>). We now use <code>MadDiff</code>&#39;s bulit-in API to model the following nonlinear program:</p><p class="math-container">\[\begin{aligned}
\min_{\{x_i\}_{i=0}^N} &amp;\sum_{i=2}^N  100(x_{i-1}^2-x_i)^2+(x_{i-1}-1)^2\\
\text{s.t.} &amp;  3x_{i+1}^3+2x_{i+2}-5+\sin(x_{i+1}-x_{i+2})\sin(x_{i+1}+x_{i+2})+4x_{i+1}-x_i e^{x_i-x_{i+1}}-3 = 0
\end{aligned}\]</p><p>We model the problem with:</p><pre><code class="language-julia hljs">N = 10000</code></pre><pre><code class="nohighlight hljs">10000</code></pre><p>First, we create a <code>MadDiffModel</code>.</p><pre><code class="language-julia hljs">m = MadDiffModel()</code></pre><pre><code class="nohighlight hljs">MadDiffModel{Float64} (not instantiated).
</code></pre><p>The variables can be created as follows:</p><pre><code class="language-julia hljs">x = [variable(m; start = mod(i,2)==1 ? -1.2 : 1.) for i=1:N];</code></pre><p>The objective can be set as follows:</p><pre><code class="language-julia hljs">objective(m, sum(100(x[i-1]^2-x[i])^2+(x[i-1]-1)^2 for i=2:N));</code></pre><p>The constraints can be set as follows:</p><pre><code class="language-julia hljs">for i=1:N-2
    constraint(m, 3x[i+1]^3+2*x[i+2]-5+sin(x[i+1]-x[i+2])sin(x[i+1]+x[i+2])+4x[i+1]-x[i]exp(x[i]-x[i+1])-3 == 0);
end</code></pre><p>The important last step is instantiating the model. This step must be taken before calling optimizers.</p><pre><code class="language-julia hljs">instantiate!(m)</code></pre><pre><code class="nohighlight hljs">MadDiffModel{Float64} (instantiated).
  Problem name: Generic
   All variables: ████████████████████ 10000  All constraints: ████████████████████ 9998  
            free: ████████████████████ 10000             free: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                lower: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                upper: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
         low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              low/upp: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           fixed: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                fixed: ████████████████████ 9998  
          infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               infeas: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
            nnzh: ( 99.96% sparsity)   19999           linear: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
                                                    nonlinear: ████████████████████ 9998  
                                                         nnzj: ( 99.97% sparsity)   29994 

  Counters:
             obj: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 grad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 cons: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
        cons_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0             cons_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 jcon: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           jgrad: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                  jac: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0              jac_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
         jac_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                jprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0            jprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
       jprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jtprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0           jtprod_lin: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
      jtprod_nln: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                 hess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0                hprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
           jhess: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0               jhprod: ⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅⋅ 0     
</code></pre><p>To solve the problem with <code>Ipopt</code>,</p><pre><code class="language-julia hljs">using NLPModelsIpopt
ipopt(m);</code></pre><pre><code class="nohighlight hljs">
******************************************************************************
This program contains Ipopt, a library for large-scale nonlinear optimization.
 Ipopt is released as open source code under the Eclipse Public License (EPL).
         For more information visit https://github.com/coin-or/Ipopt
******************************************************************************

This is Ipopt version 3.14.4, running with linear solver MUMPS 5.4.1.

Number of nonzeros in equality constraint Jacobian...:    29994
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:    19999

Total number of variables............................:    10000
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     9998
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  2.5405160e+06 2.48e+01 2.73e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  1.3512419e+06 1.49e+01 8.27e+01  -1.0 2.20e+00    -  1.00e+00 1.00e+00f  1
   2  1.5156131e+05 4.28e+00 1.36e+02  -1.0 1.43e+00    -  1.00e+00 1.00e+00f  1
   3  6.6755024e+01 3.09e-01 2.18e+01  -1.0 5.63e-01    -  1.00e+00 1.00e+00f  1
   4  6.2338933e+00 1.73e-02 8.47e-01  -1.0 2.10e-01    -  1.00e+00 1.00e+00h  1
   5  6.2324586e+00 1.15e-05 8.16e-04  -1.7 3.35e-03    -  1.00e+00 1.00e+00h  1
   6  6.2324586e+00 8.36e-12 7.97e-10  -5.7 2.00e-06    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 6

                                   (scaled)                 (unscaled)
Objective...............:   7.8692659500479645e-01    6.2324586324379885e+00
Dual infeasibility......:   7.9743417331632266e-10    6.3156786526652763e-09
Constraint violation....:   8.3555384833289281e-12    8.3555384833289281e-12
Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   7.9743417331632266e-10    6.3156786526652763e-09


Number of objective function evaluations             = 7
Number of objective gradient evaluations             = 7
Number of equality constraint evaluations            = 7
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 7
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 6
Total seconds in IPOPT                               = 1.829

EXIT: Optimal Solution Found.
</code></pre><h3 id="MadDiff-as-an-AD-backend-of-JuMP"><a class="docs-heading-anchor" href="#MadDiff-as-an-AD-backend-of-JuMP">MadDiff as an AD backend of JuMP</a><a id="MadDiff-as-an-AD-backend-of-JuMP-1"></a><a class="docs-heading-anchor-permalink" href="#MadDiff-as-an-AD-backend-of-JuMP" title="Permalink"></a></h3><p>MadDiff can be used as an automatic differentiation backend of JuMP. The problem above can be modeled in <code>JuMP</code> and solved with <code>Ipopt</code> along with <code>MadDiff</code></p><pre><code class="language-julia hljs">using JuMP, Ipopt

m = JuMP.Model(Ipopt.Optimizer)

@variable(m, x[i=1:N], start=mod(i,2)==1 ? -1.2 : 1.)
@NLobjective(m, Min, sum(100(x[i-1]^2-x[i])^2+(x[i-1]-1)^2 for i=2:N))
@NLconstraint(m, [i=1:N-2], 3x[i+1]^3+2*x[i+2]-5+sin(x[i+1]-x[i+2])sin(x[i+1]+x[i+2])+4x[i+1]-x[i]exp(x[i]-x[i+1])-3 == 0)

optimize!(m; differentiation_backend = MadDiffAD())</code></pre><pre><code class="nohighlight hljs">This is Ipopt version 3.14.4, running with linear solver MUMPS 5.4.1.

Number of nonzeros in equality constraint Jacobian...:    29994
Number of nonzeros in inequality constraint Jacobian.:        0
Number of nonzeros in Lagrangian Hessian.............:    19999

Total number of variables............................:    10000
                     variables with only lower bounds:        0
                variables with lower and upper bounds:        0
                     variables with only upper bounds:        0
Total number of equality constraints.................:     9998
Total number of inequality constraints...............:        0
        inequality constraints with only lower bounds:        0
   inequality constraints with lower and upper bounds:        0
        inequality constraints with only upper bounds:        0

iter    objective    inf_pr   inf_du lg(mu)  ||d||  lg(rg) alpha_du alpha_pr  ls
   0  2.5405160e+06 2.48e+01 2.73e+01  -1.0 0.00e+00    -  0.00e+00 0.00e+00   0
   1  1.3512419e+06 1.49e+01 8.27e+01  -1.0 2.20e+00    -  1.00e+00 1.00e+00f  1
   2  1.5156131e+05 4.28e+00 1.36e+02  -1.0 1.43e+00    -  1.00e+00 1.00e+00f  1
   3  6.6755024e+01 3.09e-01 2.18e+01  -1.0 5.63e-01    -  1.00e+00 1.00e+00f  1
   4  6.2338933e+00 1.73e-02 8.47e-01  -1.0 2.10e-01    -  1.00e+00 1.00e+00h  1
   5  6.2324586e+00 1.15e-05 8.16e-04  -1.7 3.35e-03    -  1.00e+00 1.00e+00h  1
   6  6.2324586e+00 8.36e-12 7.97e-10  -5.7 2.00e-06    -  1.00e+00 1.00e+00h  1

Number of Iterations....: 6

                                   (scaled)                 (unscaled)
Objective...............:   7.8692659500479645e-01    6.2324586324379885e+00
Dual infeasibility......:   7.9743417331632266e-10    6.3156786526652763e-09
Constraint violation....:   8.3555384833289281e-12    8.3555384833289281e-12
Variable bound violation:   0.0000000000000000e+00    0.0000000000000000e+00
Complementarity.........:   0.0000000000000000e+00    0.0000000000000000e+00
Overall NLP error.......:   7.9743417331632266e-10    6.3156786526652763e-09


Number of objective function evaluations             = 7
Number of objective gradient evaluations             = 7
Number of equality constraint evaluations            = 7
Number of inequality constraint evaluations          = 0
Number of equality constraint Jacobian evaluations   = 7
Number of inequality constraint Jacobian evaluations = 0
Number of Lagrangian Hessian evaluations             = 6
Total seconds in IPOPT                               = 1.976

EXIT: Optimal Solution Found.
</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Introduction</a><a class="docs-footer-nextpage" href="../tutorial/">How it Works »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.19 on <span class="colophon-date" title="Wednesday 8 June 2022 19:21">Wednesday 8 June 2022</span>. Using Julia version 1.6.6.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
